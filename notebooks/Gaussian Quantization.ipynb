{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import torch.distributions as tdist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Set seed\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Where to add a new import\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 1000\n",
    "n_sub_iters = 10\n",
    "batch_size = 1 \n",
    "num_atoms = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dist = tdist.MultivariateNormal(torch.tensor([0.,0.]), torch.tensor([[1.,.5],[.5,1.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_cost(x,y):\n",
    "    return torch.sqrt(torch.sum((x-y)**2, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def er_chi_unnorm(x,yj,gj, epsilon, cost_func=l2_cost):\n",
    "    return torch.exp((-cost_func(x,yj)+gj)/epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def er_chi(x, y, g, epsilon, cost_func=l2_cost):\n",
    "    chis = er_chi_unnorm(x,y,g,epsilon, cost_func)\n",
    "    return chis/ torch.sum(chis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entropic reg c-transform\n",
    "def er_ctran(x, g, y, epsilon, cost_func):\n",
    "    return -epsilon * torch.log(torch.sum(torch.exp((-cost_func(x,y)+g)/epsilon)/torch.tensor(num_atoms))) + torch.sum(g)/torch.tensor(num_atoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init vectors\n",
    "y = torch.tensor(np.random.random(size=(num_atoms,2)), requires_grad = False)\n",
    "g = torch.tensor(np.random.random(size=num_atoms), requires_grad = True)\n",
    "b = torch.ones(num_atoms)/ torch.tensor(num_atoms)\n",
    "epsilon = torch.tensor(2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f286fb51110>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ys = y.detach().numpy()\n",
    "plt.plot(ys[:,0],ys[:,1], 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tensor(tensor):\n",
    "    ys = tensor.detach().numpy()\n",
    "    plt.plot(ys[:,0],ys[:,1], 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08871112],\n",
       "       [0.10723135],\n",
       "       [0.12600297],\n",
       "       [0.10065057],\n",
       "       [0.09396664],\n",
       "       [0.09656142],\n",
       "       [0.08145145],\n",
       "       [0.12800508],\n",
       "       [0.08115129],\n",
       "       [0.09626809]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1092, 0.9650],\n",
       "        [0.8714, 0.2255],\n",
       "        [0.2152, 0.9004],\n",
       "        [0.5478, 0.1835],\n",
       "        [0.4353, 0.5188],\n",
       "        [0.9090, 0.2067],\n",
       "        [0.2014, 0.4763],\n",
       "        [0.8075, 0.9893],\n",
       "        [0.2772, 0.5237],\n",
       "        [0.3190, 0.8534]], dtype=torch.float64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1092, 0.9650],\n",
       "        [0.8714, 0.2255],\n",
       "        [0.2152, 0.9004],\n",
       "        [0.5478, 0.1835],\n",
       "        [0.4353, 0.5188],\n",
       "        [0.9090, 0.2067],\n",
       "        [0.2014, 0.4763],\n",
       "        [0.8075, 0.9893],\n",
       "        [0.2772, 0.5237],\n",
       "        [0.3190, 0.8534]], dtype=torch.float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INSTANTIATE OPTIMIZER CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = normal_dist.sample()\n",
    "chis = [er_chi_j(x, y, g, epsilon, i).detach().numpy() for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0509],\n",
       "        [0.0509],\n",
       "        [0.0509],\n",
       "        [0.0509],\n",
       "        [0.0509],\n",
       "        [0.0509],\n",
       "        [0.0509],\n",
       "        [0.0509],\n",
       "        [0.0509],\n",
       "        [0.0509]], dtype=torch.float64, grad_fn=<ExpBackward>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp((-l2_cost(x,y)+g)/epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9032, dtype=torch.float64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_cost(x, y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2824, dtype=torch.float64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_cost(x, y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1018, 0.0912, 0.1062, 0.0850, 0.1002, 0.0906, 0.0891, 0.1304, 0.0943,\n",
       "        0.1113], dtype=torch.float64, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6423, 0.8996])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f286d9e8290>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = normal_dist.sample()\n",
    "plt.plot(x.detach().numpy(), y[torch.argmax(er_chi(x, y, g, epsilon))].detach().numpy(), 'ro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2867cc4850>]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ys = y.detach().numpy()\n",
    "plt.plot(ys[:,0],ys[:,1], 'ro')\n",
    "x = normal_dist.sample()\n",
    "y_plot = y[torch.argmax(er_chi(x, y, g, epsilon))].detach().numpy()\n",
    "\n",
    "x = x.numpy()\n",
    "plt.plot(x[0],x[1],'bo')\n",
    "plt.plot(y_plot[0],y_plot[1],'bx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f286c427c50>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ys[:,0],ys[:,1], 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20143096, 0.47632823])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.8482, -0.4719])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INSTANTIATE STEP LEARNING SCHEDULER CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "optimizer_atoms = torch.optim.SGD([y], lr=learning_rate, momentum=0.9, nesterov=True)\n",
    "optimizer_map = torch.optim.SGD([g], lr=learning_rate, momentum=0.9, nesterov=True)\n",
    "\n",
    "# step_size: at how many multiples of epoch you decay\n",
    "# new_lr = lr*gamma \n",
    "\n",
    "# gamma = decaying factor\n",
    "scheduler_atoms = StepLR(optimizer_atoms, step_size=1, gamma=0.8)\n",
    "scheduler_map = StepLR(optimizer_map, step_size=1, gamma=0.8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5755, 0.4970, 0.3159, 0.6193, 0.1856, 0.2306, 0.5299, 0.5117, 0.0843,\n",
      "        0.5002], dtype=torch.float64, requires_grad=True)\n",
      "tensor(-1.0973, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "tensor([0.4311, 0.4620, 0.4211, 0.3099, 0.3372, 0.4821, 0.2670, 0.6211, 0.2980,\n",
      "        0.4206], dtype=torch.float64, requires_grad=True)\n",
      "tensor(-1.3762, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "tensor([0.4528, 0.4427, 0.4314, 0.3139, 0.3410, 0.4587, 0.2815, 0.5941, 0.3084,\n",
      "        0.4257], dtype=torch.float64, requires_grad=True)\n",
      "tensor(-1.1705, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "tensor([0.4529, 0.4461, 0.4323, 0.3047, 0.3381, 0.4608, 0.2592, 0.6327, 0.2934,\n",
      "        0.4298], dtype=torch.float64, requires_grad=True)\n",
      "tensor(-2.3651, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "tensor([0.4528, 0.4392, 0.4328, 0.3142, 0.3471, 0.4531, 0.2836, 0.5863, 0.3122,\n",
      "        0.4287], dtype=torch.float64, requires_grad=True)\n",
      "tensor(-0.6908, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "tensor([0.4627, 0.4376, 0.4340, 0.3159, 0.3361, 0.4534, 0.2943, 0.5823, 0.3140,\n",
      "        0.4196], dtype=torch.float64, requires_grad=True)\n",
      "tensor(-0.7591, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "tensor([0.4888, 0.4158, 0.4554, 0.2885, 0.3289, 0.4317, 0.2804, 0.6151, 0.3045,\n",
      "        0.4408], dtype=torch.float64, requires_grad=True)\n",
      "tensor(-1.0960, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "tensor([0.4750, 0.4284, 0.4495, 0.2806, 0.3266, 0.4457, 0.2683, 0.6404, 0.2950,\n",
      "        0.4406], dtype=torch.float64, requires_grad=True)\n",
      "tensor(-0.7647, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "tensor([0.4571, 0.4453, 0.4342, 0.3029, 0.3304, 0.4635, 0.2732, 0.6175, 0.2984,\n",
      "        0.4276], dtype=torch.float64, requires_grad=True)\n",
      "tensor(-0.9419, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "tensor([0.4580, 0.4457, 0.4377, 0.2940, 0.3296, 0.4634, 0.2597, 0.6378, 0.2907,\n",
      "        0.4333], dtype=torch.float64, requires_grad=True)\n",
      "tensor(-0.4624, dtype=torch.float64, grad_fn=<NegBackward>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_iters):\n",
    "    x = normal_dist.sample()\n",
    "\n",
    "    # Clear gradients w.r.t. parameters\n",
    "    optimizer_map.zero_grad()\n",
    "\n",
    "    # Get dual objective to maximise\n",
    "    dual_objective = er_ctran(x, g, y, epsilon, l2_cost)\n",
    "    map_loss = -dual_objective\n",
    "\n",
    "    # Getting gradients w.r.t. parameters\n",
    "    map_loss.backward()\n",
    "    optimizer_map.step()\n",
    "    \n",
    "    # Updating parameters\n",
    "    if i % 100 == 0:\n",
    "        print(g)\n",
    "        scheduler_map.step()\n",
    "        print(map_loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min Max Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        ...,\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], dtype=torch.float64, requires_grad=True)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        ...,\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], dtype=torch.float64, requires_grad=True)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        ...,\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], dtype=torch.float64, requires_grad=True)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        ...,\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], dtype=torch.float64, requires_grad=True)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        ...,\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], dtype=torch.float64, requires_grad=True)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        ...,\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], dtype=torch.float64, requires_grad=True)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        ...,\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], dtype=torch.float64, requires_grad=True)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        ...,\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], dtype=torch.float64, requires_grad=True)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        ...,\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], dtype=torch.float64, requires_grad=True)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "tensor([[nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        ...,\n",
      "        [nan, nan],\n",
      "        [nan, nan],\n",
      "        [nan, nan]], dtype=torch.float64, requires_grad=True)\n",
      "tensor(nan, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n",
      "Loss: nan\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_iters):\n",
    "    for _ in range(n_sub_iters):\n",
    "        # sample x\n",
    "        x = normal_dist.sample()\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer_map.zero_grad()\n",
    "        \n",
    "        # Get dual objective to maximise\n",
    "        dual_objective = er_ctran(x, g, y, epsilon, l2_cost)\n",
    "        map_loss = -dual_objective\n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        map_loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer_map.step()\n",
    "        \n",
    "    for _ in range(n_sub_iters):\n",
    "        # sample x\n",
    "        x = normal_dist.sample()\n",
    "\n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer_atoms.zero_grad()\n",
    "        \n",
    "        # Get loss objective to minimise\n",
    "        atoms_loss = er_ctran(x, g, y, epsilon, l2_cost)\n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        atoms_loss.backward()\n",
    "\n",
    "        # Updating parameters\n",
    "        optimizer_atoms.step()\n",
    "    \n",
    "    # Updating parameters\n",
    "    if i % 100 == 0:\n",
    "        print(g)\n",
    "        print(map_loss)\n",
    "        # Decay Learning Rate\n",
    "        scheduler_atoms.step()\n",
    "        scheduler_map.step()\n",
    "    \n",
    "    print(\"Loss: {0}\".format(map_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        ...,\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan]], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        ...,\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan]], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
